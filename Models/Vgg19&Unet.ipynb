{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf514c1-e26c-45d4-9def-1b661bd02e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import visualkeras\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b9f53-82d4-4e80-a337-3476b5fe6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dc304-b2da-4168-adce-b0acdc49386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2874f3f-9162-44fc-ae98-91251bfd1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99bcc1-4ec0-4163-bddb-be1ed4397180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "\n",
    "    def __init__(self, path, split_ratio, x, y, color_space='rgb'):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "        self.color_space = color_space\n",
    "        self.path_train_images = path + \"train/train/image/\"\n",
    "        self.path_train_labels = path + \"train/train/mask/\"\n",
    "        self.image_file_list = get_png_filename_list(self.path_train_images)\n",
    "        self.label_file_list = get_png_filename_list(self.path_train_labels)\n",
    "        self.split_index = int(split_ratio * len(self.image_file_list))\n",
    "        self.x_train_file_list = self.image_file_list[self.split_index:]\n",
    "        self.y_train_file_list = self.label_file_list[self.split_index:]\n",
    "        self.x_val_file_list = self.image_file_list[:self.split_index]\n",
    "        self.y_val_file_list = self.label_file_list[:self.split_index]\n",
    "\n",
    "    def generate_data(self, batch_size, train=False, val=False, test=False):\n",
    "        \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "        try:\n",
    "            if train is True:\n",
    "                image_file_list = self.x_train_file_list\n",
    "                label_file_list = self.y_train_file_list\n",
    "            elif val is True:\n",
    "                image_file_list = self.x_val_file_list\n",
    "                label_file_list = self.y_val_file_list\n",
    "            elif test is True:\n",
    "                image_file_list = self.x_test_file_list\n",
    "                label_file_list = self.y_test_file_list\n",
    "        except ValueError:\n",
    "            print('one of train or val or test need to be True')\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            image_batch = []\n",
    "            label_batch = []\n",
    "            for b in range(batch_size):\n",
    "                if i == len(self.x_train_file_list):\n",
    "                    i = 0\n",
    "                if i < len(image_file_list):\n",
    "                    sample_image_filename = image_file_list[i]\n",
    "                    sample_label_filename = label_file_list[i]\n",
    "                    if train or val:\n",
    "                        image = cv2.imread(self.path_train_images + sample_image_filename, 1)\n",
    "                        label = cv2.imread(self.path_train_labels + sample_label_filename, 0)\n",
    "                    elif test is True:\n",
    "                        image = cv2.imread(self.path_test_images + sample_image_filename, 1)\n",
    "                        label = cv2.imread(self.path_test_labels + sample_label_filename, 0)\n",
    "                    # image, label = self.change_color_space(image, label, self.color_space)\n",
    "                    label = np.expand_dims(label, axis=2)\n",
    "                    if image.shape[0] == self.x and image.shape[1] == self.y:\n",
    "                        image_batch.append(image.astype(\"float32\"))\n",
    "                    else:\n",
    "                        print('the input image shape is not {}x{}'.format(self.x, self.y))\n",
    "                    if label.shape[0] == self.x and label.shape[1] == self.y:\n",
    "                        label_batch.append(label.astype(\"float32\"))\n",
    "                    else:\n",
    "                        print('the input label shape is not {}x{}'.format(self.x, self.y))\n",
    "                i += 1\n",
    "            if image_batch and label_batch:\n",
    "                image_batch = normalize(np.array(image_batch))\n",
    "                label_batch = normalize(np.array(label_batch))\n",
    "                yield (image_batch, label_batch)\n",
    "\n",
    "    def get_num_data_points(self, train=False, val=False):\n",
    "        try:\n",
    "            image_file_list = self.x_train_file_list if val is False and train is True else self.x_val_file_list\n",
    "        except ValueError:\n",
    "            print('one of train or val need to be True')\n",
    "\n",
    "        return len(image_file_list)\n",
    "\n",
    "    def shuffle_image_label_lists_together(self):\n",
    "        combined = list(zip(self.image_file_list, self.label_file_list))\n",
    "        random.shuffle(combined)\n",
    "        return zip(*combined)\n",
    "    \n",
    "def normalize(arr):\n",
    "    diff = np.amax(arr) - np.amin(arr)\n",
    "    diff = 255 if diff == 0 else diff\n",
    "    arr = arr / np.absolute(diff)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_png_filename_list(path):\n",
    "    file_list = []\n",
    "    for FileNameLength in range(0, 500):\n",
    "        for dirName, subdirList, fileList in os.walk(path):\n",
    "            for filename in fileList:\n",
    "                if \".png\" in filename.lower() and len(filename) == FileNameLength:\n",
    "                    file_list.append(filename)\n",
    "            break\n",
    "    file_list.sort()\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd24a38-ea78-4340-8bc4-2b8c84415532",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_x=224\n",
    "input_dim_y=224\n",
    "IMAGE_SIZE=224\n",
    "n_filters = 32\n",
    "dataset = 'dataset'\n",
    "data_gen = DataGen('C:/Users/tarek/Downloads/wound/' + dataset + '/', split_ratio=0.2, x=input_dim_x, y=input_dim_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d672a89-b025-4e3f-9efa-0520c52bdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images_bilinear(X, height_factor=1, width_factor=1, target_height=None, target_width=None, data_format='default'):\n",
    "    '''Resizes the images contained in a 4D tensor of shape\n",
    "    - [batch, channels, height, width] (for 'channels_first' data_format)\n",
    "    - [batch, height, width, channels] (for 'channels_last' data_format)\n",
    "    by a factor of (height_factor, width_factor). Both factors should be\n",
    "    positive integers.\n",
    "    '''\n",
    "    if data_format == 'default':\n",
    "        data_format = K.image_data_format()\n",
    "    if data_format == 'channels_first':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[2:]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = K.permute_dimensions(X, [0, 2, 3, 1])\n",
    "        X = tf.image.resize(X, new_shape)\n",
    "        X = K.permute_dimensions(X, [0, 3, 1, 2])\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, None, target_height, target_width))\n",
    "        else:\n",
    "            X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n",
    "        return X\n",
    "    elif data_format == 'channels_last':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[1:3]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = tf.image.resize(X, new_shape)\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, target_height, target_width, None))\n",
    "        else:\n",
    "            X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n",
    "        return X\n",
    "    else:\n",
    "        raise Exception('Invalid data_format: ' + data_format)\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(1, 1), target_size=None, data_format='default', **kwargs):\n",
    "        if data_format == 'default':\n",
    "            data_format = K.image_data_format()\n",
    "        self.size = tuple(size)\n",
    "        if target_size is not None:\n",
    "            self.target_size = tuple(target_size)\n",
    "        else:\n",
    "            self.target_size = None\n",
    "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {tf, th}'\n",
    "        self.data_format = data_format\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            width = int(self.size[0] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[3] if input_shape[3] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    width,\n",
    "                    height)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            width = int(self.size[0] * input_shape[1] if input_shape[1] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    width,\n",
    "                    height,\n",
    "                    input_shape[3])\n",
    "        else:\n",
    "            raise Exception('Invalid data_format: ' + self.data_format)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.target_size is not None:\n",
    "            return resize_images_bilinear(x, target_height=self.target_size[0], target_width=self.target_size[1], data_format=self.data_format)\n",
    "        else:\n",
    "            return resize_images_bilinear(x, height_factor=self.size[0], width_factor=self.size[1], data_format=self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'size': self.size, 'target_size': self.target_size}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450accd9-2805-41f7-ab37-ff5c45bcbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input_image\")\n",
    "    \n",
    "    encoder = VGG19(input_tensor=inputs, weights=\"imagenet\", include_top=False)\n",
    "    skip_connection_names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n",
    "    encoder_output = encoder.get_layer(\"block5_conv4\").output\n",
    "    \n",
    "    f = [16, 32, 48, 64]\n",
    "    x = encoder_output\n",
    "    for i in range(1, len(skip_connection_names)+1, 1):\n",
    "        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Concatenate()([x, x_skip])\n",
    "        \n",
    "        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0fc92-fb75-4a88-88ee-62b66aaa2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()\n",
    "model.summary()\n",
    "visualkeras.layered_view(model,draw_volume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a24b1d-2325-4e0d-847b-36783498f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "loss = 'binary_crossentropy'\n",
    "es = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=False),\n",
    "    ModelCheckpoint('C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\update\\\\2ndDataRoom\\\\Vgg19&Unet\\\\model-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffb5c2-0644-4854-833c-b849913a28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2ca9c-b205-4275-8d87-72f2721a1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(truth, prediction):\n",
    "    TP = K.sum(K.round(K.clip(truth * prediction, 0, 1)))\n",
    "    P = K.sum(K.round(K.clip(truth, 0, 1)))\n",
    "    return TP / (P + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60013a-fbc0-44d2-b733-aa641cc6ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(truth, prediction):\n",
    "    TP = K.sum(K.round(K.clip(truth * prediction, 0, 1)))\n",
    "    FP = K.sum(K.round(K.clip((1-truth) * prediction, 0, 1)))\n",
    "    return TP / (TP + FP + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc369485-3dbc-4903-a4f1-28319def5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=[dice_coef, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc7bff-307a-46b8-9de9-7c2a17dfd7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(data_gen.generate_data(batch_size=batch_size, train=True),\n",
    "                            steps_per_epoch=int(data_gen.get_num_data_points(train=True) / batch_size),\n",
    "                            callbacks=es,\n",
    "                            validation_data=data_gen.generate_data(batch_size=batch_size, val=True),\n",
    "                            validation_steps=int(data_gen.get_num_data_points(val=True) / batch_size),\n",
    "                            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57441e-d177-468e-8698-7e9eaae5a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\dataset\\\\test'\n",
    "BATCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df2d30-31f5-411a-b9cd-c7fdc7a93b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a38d2e-30e3-44a5-9a21-129e39956f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y.set_shape([IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(map_func=tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910ce9e-6d5e-412a-8be4-912885df6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "test_x = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "test_y = sorted(glob(os.path.join(path, \"labels/*\")))\n",
    "test_dataset = tf_dataset(test_x, test_y, batch=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d87d5-065d-402f-8502-0fcc03bdd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CustomObjectScope({'BilinearUpSampling2D':BilinearUpSampling2D}):\n",
    "    model = keras.models.load_model('C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\update\\\\2ndDataRoom\\\\Vgg19&Unet\\\\model-011.h5',compile=False)\n",
    "print(len(test_y))\n",
    "print(len(test_x))\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=[dice_coef, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271672cc-41d3-4bfc-87a0-9ed8c3266894",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = (len(test_x)//BATCH)\n",
    "if len(test_x) % BATCH != 0:\n",
    "    test_steps += 1\n",
    "model.evaluate(test_dataset, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec116442-8704-4aa7-ad52-96d0a78439d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e8d7b-42c9-45f8-8a55-b2ffb53b1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d3947-f12d-40d4-984f-32e73d4ce037",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(test_x[10:20], test_y[10:20])):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 10, 3))\n",
    "\n",
    "    all_images = [\n",
    "        x, white_line,\n",
    "        mask_parse(y), white_line,\n",
    "        mask_parse(y_pred)\n",
    "    ]\n",
    "    image = np.concatenate(all_images, axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(56, 56))\n",
    "    a = fig.add_subplot(1, 1, 1)\n",
    "    imgplot = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43a9fe-5f6d-4522-b530-57bc3d1e38d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
