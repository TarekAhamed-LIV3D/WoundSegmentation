{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6d2fd-2b87-4c03-90c6-1b0eea7b02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D\n",
    "from keras.layers import *\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159993a1-f435-46d9-8657-9e22e24d2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67b286-7afd-494d-8354-3af3c6fbee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cf2f2-c3fa-4be0-b4ca-2ff10acf61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0113b-910c-486e-8c17-1b7945b8f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "\n",
    "    def __init__(self, path, split_ratio, x, y, color_space='rgb'):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "        self.color_space = color_space\n",
    "        self.path_train_images = path + \"train/train/image/\"\n",
    "        self.path_train_labels = path + \"train/train/mask/\"\n",
    "        self.image_file_list = get_png_filename_list(self.path_train_images)\n",
    "        self.label_file_list = get_png_filename_list(self.path_train_labels)\n",
    "        self.split_index = int(split_ratio * len(self.image_file_list))\n",
    "        self.x_train_file_list = self.image_file_list[self.split_index:]\n",
    "        self.y_train_file_list = self.label_file_list[self.split_index:]\n",
    "        self.x_val_file_list = self.image_file_list[:self.split_index]\n",
    "        self.y_val_file_list = self.label_file_list[:self.split_index]\n",
    "\n",
    "    def generate_data(self, batch_size, train=False, val=False, test=False):\n",
    "        \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "        try:\n",
    "            if train is True:\n",
    "                image_file_list = self.x_train_file_list\n",
    "                label_file_list = self.y_train_file_list\n",
    "            elif val is True:\n",
    "                image_file_list = self.x_val_file_list\n",
    "                label_file_list = self.y_val_file_list\n",
    "        except ValueError:\n",
    "            print('one of train or val or test need to be True')\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            image_batch = []\n",
    "            label_batch = []\n",
    "            for b in range(batch_size):\n",
    "                if i == len(self.x_train_file_list):\n",
    "                    i = 0\n",
    "                if i < len(image_file_list):\n",
    "                    sample_image_filename = image_file_list[i]\n",
    "                    sample_label_filename = label_file_list[i]\n",
    "                    if train or val:\n",
    "                        image = cv2.imread(self.path_train_images + sample_image_filename, 1)\n",
    "                        label = cv2.imread(self.path_train_labels + sample_label_filename, 0)\n",
    "                    elif test is True:\n",
    "                        image = cv2.imread(self.path_test_images + sample_image_filename, 1)\n",
    "                        label = cv2.imread(self.path_test_labels + sample_label_filename, 0)\n",
    "                    # image, label = self.change_color_space(image, label, self.color_space)\n",
    "                    label = np.expand_dims(label, axis=2)\n",
    "                    if image.shape[0] == self.x and image.shape[1] == self.y:\n",
    "                        image_batch.append(image.astype(\"float32\"))\n",
    "                    else:\n",
    "                        print('the input image shape is not {}x{}'.format(self.x, self.y))\n",
    "                    if label.shape[0] == self.x and label.shape[1] == self.y:\n",
    "                        label_batch.append(label.astype(\"float32\"))\n",
    "                    else:\n",
    "                        print('the input label shape is not {}x{}'.format(self.x, self.y))\n",
    "                i += 1\n",
    "            if image_batch and label_batch:\n",
    "                image_batch = normalize(np.array(image_batch))\n",
    "                label_batch = normalize(np.array(label_batch))\n",
    "                yield (image_batch, label_batch)\n",
    "\n",
    "    def get_num_data_points(self, train=False, val=False):\n",
    "        try:\n",
    "            image_file_list = self.x_train_file_list if val is False and train is True else self.x_val_file_list\n",
    "        except ValueError:\n",
    "            print('one of train or val need to be True')\n",
    "\n",
    "        return len(image_file_list)\n",
    "\n",
    "    def shuffle_image_label_lists_together(self):\n",
    "        combined = list(zip(self.image_file_list, self.label_file_list))\n",
    "        random.shuffle(combined)\n",
    "        return zip(*combined)\n",
    "    \n",
    "def normalize(arr):\n",
    "    diff = np.amax(arr) - np.amin(arr)\n",
    "    diff = 255 if diff == 0 else diff\n",
    "    arr = arr / np.absolute(diff)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_png_filename_list(path):\n",
    "    file_list = []\n",
    "    for FileNameLength in range(0, 500):\n",
    "        for dirName, subdirList, fileList in os.walk(path):\n",
    "            for filename in fileList:\n",
    "                if \".png\" in filename.lower() and len(filename) == FileNameLength:\n",
    "                    file_list.append(filename)\n",
    "            break\n",
    "    file_list.sort()\n",
    "    return file_list\n",
    "\n",
    "def get_jpg_filename_list(path):\n",
    "    file_list = []\n",
    "    for FileNameLength in range(0, 500):\n",
    "        for dirName, subdirList, fileList in os.walk(path):\n",
    "            for filename in fileList:\n",
    "                # check file extension\n",
    "                if \".jpg\" in filename.lower() and len(filename) == FileNameLength:\n",
    "                    file_list.append(filename)\n",
    "            break\n",
    "    file_list.sort()\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def load_jpg_images(path):\n",
    "    file_list = get_jpg_filename_list(path)\n",
    "    temp_list = []\n",
    "    for filename in file_list:\n",
    "        img = cv2.imread(path + filename, 1)\n",
    "        temp_list.append(img.astype(\"float32\"))\n",
    "\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list, file_list\n",
    "\n",
    "\n",
    "def load_png_images(path):\n",
    "    temp_list = []\n",
    "    file_list = get_png_filename_list(path)\n",
    "    for filename in file_list:\n",
    "        img = cv2.imread(path + filename, 1)\n",
    "        temp_list.append(img.astype(\"float32\"))\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list, file_list\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    path_train_images = path + \"train/train/images/\"\n",
    "    path_train_labels = path + \"train/train/labels/\"\n",
    "    x_train, train_image_filenames_list = load_png_images(path_train_images)\n",
    "    y_train, train_label_filenames_list = load_png_images(path_train_labels)\n",
    "    x_train = normalize(x_train)\n",
    "    y_train = normalize(y_train)\n",
    "    return x_train, y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b3b81-97e3-46e9-8418-b1b786445ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_x=224\n",
    "input_dim_y=224\n",
    "n_filters = 32\n",
    "dataset = 'dataset'\n",
    "data_gen = DataGen('C:/Users/tarek/Downloads/wound/' + dataset + '/', split_ratio=0.2, x=input_dim_x, y=input_dim_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82752afd-1e81-47b1-ac7a-5c860b6409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images_bilinear(X, height_factor=1, width_factor=1, target_height=None, target_width=None, data_format='default'):\n",
    "    '''Resizes the images contained in a 4D tensor of shape\n",
    "    - [batch, channels, height, width] (for 'channels_first' data_format)\n",
    "    - [batch, height, width, channels] (for 'channels_last' data_format)\n",
    "    by a factor of (height_factor, width_factor). Both factors should be\n",
    "    positive integers.\n",
    "    '''\n",
    "    if data_format == 'default':\n",
    "        data_format = K.image_data_format()\n",
    "    if data_format == 'channels_first':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[2:]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = K.permute_dimensions(X, [0, 2, 3, 1])\n",
    "        X = tf.image.resize(X, new_shape)\n",
    "        X = K.permute_dimensions(X, [0, 3, 1, 2])\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, None, target_height, target_width))\n",
    "        else:\n",
    "            X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n",
    "        return X\n",
    "    elif data_format == 'channels_last':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[1:3]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = tf.image.resize(X, new_shape)\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, target_height, target_width, None))\n",
    "        else:\n",
    "            X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n",
    "        return X\n",
    "    else:\n",
    "        raise Exception('Invalid data_format: ' + data_format)\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(1, 1), target_size=None, data_format='default', **kwargs):\n",
    "        if data_format == 'default':\n",
    "            data_format = K.image_data_format()\n",
    "        self.size = tuple(size)\n",
    "        if target_size is not None:\n",
    "            self.target_size = tuple(target_size)\n",
    "        else:\n",
    "            self.target_size = None\n",
    "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {tf, th}'\n",
    "        self.data_format = data_format\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            width = int(self.size[0] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[3] if input_shape[3] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    width,\n",
    "                    height)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            width = int(self.size[0] * input_shape[1] if input_shape[1] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    width,\n",
    "                    height,\n",
    "                    input_shape[3])\n",
    "        else:\n",
    "            raise Exception('Invalid data_format: ' + self.data_format)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.target_size is not None:\n",
    "            return resize_images_bilinear(x, target_height=self.target_size[0], target_width=self.target_size[1], data_format=self.data_format)\n",
    "        else:\n",
    "            return resize_images_bilinear(x, height_factor=self.size[0], width_factor=self.size[1], data_format=self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'size': self.size, 'target_size': self.target_size}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5ae8e-8007-431a-a741-84efba4cd85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet:\n",
    "    def __init__(self, n_filters, input_dim_x, input_dim_y, num_channels):\n",
    "        self.input_dim_x = input_dim_x\n",
    "        self.input_dim_y = input_dim_y\n",
    "        self.n_filters = n_filters\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def get_SegNet(self):\n",
    "        convnet_input = Input(shape=(self.input_dim_x, self.input_dim_y, self.num_channels))\n",
    "\n",
    "        encoder_conv1 = Conv2D(self.n_filters, kernel_size=9, activation='relu', padding='same')(convnet_input)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(encoder_conv1)\n",
    "        encoder_conv2 = Conv2D(self.n_filters, kernel_size=5, activation='relu', padding='same')(pool1)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(encoder_conv2)\n",
    "        encoder_conv3 = Conv2D(self.n_filters * 2, kernel_size=5, activation='relu', padding='same')(pool2)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(encoder_conv3)\n",
    "        encoder_conv4 = Conv2D(self.n_filters * 2, kernel_size=5, activation='relu', padding='same')(pool3)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(encoder_conv4)\n",
    "\n",
    "        conv5 = Conv2D(self.n_filters, kernel_size=5, activation='relu', padding='same')(pool4)\n",
    "\n",
    "        decoder_conv6 = Conv2D(self.n_filters, kernel_size=7, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv5))\n",
    "        decoder_conv7 = Conv2D(self.n_filters, kernel_size=5, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(decoder_conv6))\n",
    "        decoder_conv8 = Conv2D(self.n_filters, kernel_size=5, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(decoder_conv7))\n",
    "        #decoder_conv9 = Conv2D(self.n_filters, kernel_size=5, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(decoder_conv8))\n",
    "        decoder_conv9 = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(UpSampling2D(size=(2, 2))(decoder_conv8))\n",
    "\n",
    "        return Model(outputs=decoder_conv9, inputs=convnet_input), 'SegNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a476861-e2b4-4e3c-b0ca-966748e95139",
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet = SegNet(n_filters, input_dim_x, input_dim_y, num_channels=3)\n",
    "model, model_name = segnet.get_SegNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b480330-5cf7-44f8-bb4a-f41f39a33db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model,draw_volume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad90f9-03c3-416a-81f1-55edcc23b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "loss = 'binary_crossentropy'\n",
    "es = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=False),\n",
    "    ModelCheckpoint('C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\update\\\\SegNet\\\\model-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd89fd-bfd5-495a-bd36-befc9565ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d25aa-149e-4782-828e-18ddd264a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(truth, prediction):\n",
    "    TP = K.sum(K.round(K.clip(truth * prediction, 0, 1)))\n",
    "    FP = K.sum(K.round(K.clip((1-truth) * prediction, 0, 1)))\n",
    "    return TP / (TP + FP + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa573dd0-2712-40ad-a193-878ab3313aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(truth, prediction):\n",
    "    TP = K.sum(K.round(K.clip(truth * prediction, 0, 1)))\n",
    "    P = K.sum(K.round(K.clip(truth, 0, 1)))\n",
    "    return TP / (P + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d697df-964f-48ef-bb7f-0e51225d4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=[dice_coef, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af74c35-9b86-4df2-88d5-641c22557ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(data_gen.generate_data(batch_size=batch_size, train=True),\n",
    "                            steps_per_epoch=int(data_gen.get_num_data_points(train=True) / batch_size),\n",
    "                            callbacks=es,\n",
    "                            validation_data=data_gen.generate_data(batch_size=batch_size, val=True),\n",
    "                            validation_steps=int(data_gen.get_num_data_points(val=True) / batch_size),\n",
    "                            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248a97b-4b5f-4851-8fe3-92b17fbce6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\dataset\\\\test'\n",
    "BATCH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b137f22-2d4b-4d6d-b212-ad045831faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e80c5-cf71-4a93-a5d2-2524bed8f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y.set_shape([IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(map_func=tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf19149-201d-4173-92d2-795b17e64346",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "test_x = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "test_y = sorted(glob(os.path.join(path, \"labels/*\")))\n",
    "test_dataset = tf_dataset(test_x, test_y, batch=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71466764-a7ce-434c-bdae-5b5b48ea5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "with CustomObjectScope({'BilinearUpSampling2D':BilinearUpSampling2D}):\n",
    "    model = keras.models.load_model('C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\update\\\\SegNet\\\\model-022.h5',compile=False)\n",
    "print(len(test_y))\n",
    "print(len(test_x))\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=[dice_coef, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f17931-dfba-4504-a803-351cec15c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = (len(test_x)//BATCH)\n",
    "if len(test_x) % BATCH != 0:\n",
    "    test_steps += 1\n",
    "model.evaluate(test_dataset, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6212238-b93d-49ff-bb97-008c6c83cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a22697-6d8b-4a2d-b56d-1bb4e058daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140ba69-85da-49d1-88bf-f7febffc9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(test_x[10:20], test_y[10:20])):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 10, 3))\n",
    "\n",
    "    all_images = [\n",
    "        x, white_line,\n",
    "        mask_parse(y), white_line,\n",
    "        mask_parse(y_pred)\n",
    "    ]\n",
    "    image = np.concatenate(all_images, axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(56, 56))\n",
    "    a = fig.add_subplot(1, 1, 1)\n",
    "    imgplot = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd1dc1-a0fc-467e-86c5-86c359880d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
