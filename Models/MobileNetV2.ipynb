{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a993c41-6d35-427f-8b9d-fecc01ca9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D\n",
    "from keras.layers import *\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Add\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import DepthwiseConv2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c729c05f-8f55-49f1-b7f0-7c97544a15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH_X = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\"\n",
    "WEIGHTS_PATH_MOBILE = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5\"\n",
    "WEIGHTS_PATH_X_CS = \"https://github.com/rdiazgar/keras-deeplab-v3-plus/releases/download/1.2/deeplabv3_xception_tf_dim_ordering_tf_kernels_cityscapes.h5\"\n",
    "WEIGHTS_PATH_MOBILE_CS = \"https://github.com/rdiazgar/keras-deeplab-v3-plus/releases/download/1.2/deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels_cityscapes.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec873928-c7ce-4b7e-8363-90c8941b2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearUpsampling(Layer):\n",
    "    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\n",
    "       Args:\n",
    "           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\n",
    "           output_size: used instead of upsampling arg if passed!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\n",
    "\n",
    "        super(BilinearUpsampling, self).__init__(**kwargs)\n",
    "\n",
    "        self.data_format = K.image_data_format()\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        if output_size:\n",
    "            self.output_size = conv_utils.normalize_tuple(\n",
    "                output_size, 2, 'output_size')\n",
    "            self.upsampling = None\n",
    "        else:\n",
    "            self.output_size = None\n",
    "            self.upsampling = conv_utils.normalize_tuple(\n",
    "                upsampling, 2, 'upsampling')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.upsampling:\n",
    "            height = self.upsampling[0] * \\\n",
    "                input_shape[1] if input_shape[1] is not None else None\n",
    "            width = self.upsampling[1] * \\\n",
    "                input_shape[2] if input_shape[2] is not None else None\n",
    "        else:\n",
    "            height = self.output_size[0]\n",
    "            width = self.output_size[1]\n",
    "        return (input_shape[0],\n",
    "                height,\n",
    "                width,\n",
    "                input_shape[3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.upsampling:\n",
    "            return K.tf.compat.v1.image.resize(inputs, (inputs.shape[1] * self.upsampling[0],\n",
    "                                                       inputs.shape[2] * self.upsampling[1]),\n",
    "                                              align_corners=True)\n",
    "        else:\n",
    "            return K.tf.compat.v1.image.resize(inputs, (self.output_size[0],\n",
    "                                                       self.output_size[1]),\n",
    "                                              align_corners=True)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'upsampling': self.upsampling,\n",
    "                  'output_size': self.output_size,\n",
    "                  'data_format': self.data_format}\n",
    "        base_config = super(BilinearUpsampling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n",
    "    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n",
    "        Implements right \"same\" padding for even kernel sizes\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & poinwise convs\n",
    "            epsilon: epsilon to use in BN layer\n",
    "    \"\"\"\n",
    "\n",
    "    if stride == 1:\n",
    "        depth_padding = 'same'\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        depth_padding = 'valid'\n",
    "\n",
    "    if not depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n",
    "                        padding=depth_padding, use_bias=False, name=prefix + '_depthwise')(x)\n",
    "    x = BatchNormalization(name=prefix + '_depthwise_BN', epsilon=epsilon)(x)\n",
    "    if depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (1, 1), padding='same',\n",
    "               use_bias=False, name=prefix + '_pointwise')(x)\n",
    "    x = BatchNormalization(name=prefix + '_pointwise_BN', epsilon=epsilon)(x)\n",
    "    if depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n",
    "    \"\"\"Implements right 'same' padding for even kernel sizes\n",
    "        Without this there is a 1 pixel drift when stride = 2\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "    \"\"\"\n",
    "    if stride == 1:\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='same', use_bias=False,\n",
    "                      dilation_rate=(rate, rate),\n",
    "                      name=prefix)(x)\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='valid', use_bias=False,\n",
    "                      dilation_rate=(rate, rate),\n",
    "                      name=prefix)(x)\n",
    "\n",
    "\n",
    "def _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n",
    "                    rate=1, depth_activation=False, return_skip=False):\n",
    "    \"\"\" Basic building block of modified Xception network\n",
    "        Args:\n",
    "            inputs: input tensor\n",
    "            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n",
    "            prefix: prefix before name\n",
    "            skip_connection_type: one of {'conv','sum','none'}\n",
    "            stride: stride at last depthwise conv\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & pointwise convs\n",
    "            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n",
    "            \"\"\"\n",
    "    residual = inputs\n",
    "    for i in range(3):\n",
    "        residual = SepConv_BN(residual,\n",
    "                              depth_list[i],\n",
    "                              prefix + '_separable_conv{}'.format(i + 1),\n",
    "                              stride=stride if i == 2 else 1,\n",
    "                              rate=rate,\n",
    "                              depth_activation=depth_activation)\n",
    "        if i == 1:\n",
    "            skip = residual\n",
    "    if skip_connection_type == 'conv':\n",
    "        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n",
    "                                kernel_size=1,\n",
    "                                stride=stride)\n",
    "        shortcut = BatchNormalization(name=prefix + '_shortcut_BN')(shortcut)\n",
    "        outputs = layers.add([residual, shortcut])\n",
    "    elif skip_connection_type == 'sum':\n",
    "        outputs = layers.add([residual, inputs])\n",
    "    elif skip_connection_type == 'none':\n",
    "        outputs = residual\n",
    "    if return_skip:\n",
    "        return outputs, skip\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\n",
    "    in_channels = inputs.shape[-1]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    x = inputs\n",
    "    prefix = 'expanded_conv_{}_'.format(block_id)\n",
    "    if block_id:\n",
    "        # Expand\n",
    "\n",
    "        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n",
    "                   use_bias=False, activation=None,\n",
    "                   name=prefix + 'expand')(x)\n",
    "        x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n",
    "                               name=prefix + 'expand_BN')(x)\n",
    "        x = Activation(relu6, name=prefix + 'expand_relu')(x)\n",
    "    else:\n",
    "        prefix = 'expanded_conv_'\n",
    "    # Depthwise\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\n",
    "                        use_bias=False, padding='same', dilation_rate=(rate, rate),\n",
    "                        name=prefix + 'depthwise')(x)\n",
    "    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n",
    "                           name=prefix + 'depthwise_BN')(x)\n",
    "\n",
    "    x = Activation(relu6, name=prefix + 'depthwise_relu')(x)\n",
    "\n",
    "    # Project\n",
    "    x = Conv2D(pointwise_filters,\n",
    "               kernel_size=1, padding='same', use_bias=False, activation=None,\n",
    "               name=prefix + 'project')(x)\n",
    "    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n",
    "                           name=prefix + 'project_BN')(x)\n",
    "\n",
    "    if skip_connection:\n",
    "        return Add(name=prefix + 'add')([inputs, x])\n",
    "\n",
    "    # if in_channels == pointwise_filters and stride == 1:\n",
    "    #    return Add(name='res_connect_' + str(block_id))([inputs, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def Deeplabv3(weights='pascal_voc', input_tensor=None, input_shape=(512, 512, 3), classes=21, backbone='mobilenetv2'\n",
    "              , OS=16, alpha=1.):\n",
    "    \"\"\" Instantiates the Deeplabv3+ architecture\n",
    "    Optionally loads weights pre-trained\n",
    "    on PASCAL VOC. This model is available for TensorFlow only,\n",
    "    and can only be used with inputs following the TensorFlow\n",
    "    data format `(width, height, channels)`.\n",
    "    # Arguments\n",
    "        weights: one of 'pascal_voc' (pre-trained on pascal voc)\n",
    "            or None (random initialization)\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: shape of input image. format HxWxC\n",
    "            PASCAL VOC model was trained on (512,512,3) images\n",
    "        classes: number of desired classes. If classes != 21,\n",
    "            last layer is initialized randomly\n",
    "        backbone: backbone to use. one of {'xception','mobilenetv2'}\n",
    "        OS: determines input_shape/feature_extractor_output ratio. One of {8,16}.\n",
    "            Used only for xception backbone.\n",
    "        alpha: controls the width of the MobileNetV2 network. This is known as the\n",
    "            width multiplier in the MobileNetV2 paper.\n",
    "                - If `alpha` < 1.0, proportionally decreases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` > 1.0, proportionally increases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` = 1, default number of filters from the paper\n",
    "                    are used at each layer.\n",
    "            Used only for mobilenetv2 backbone\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "        ValueError: in case of invalid argument for `weights` or `backbone`\n",
    "    \"\"\"\n",
    "\n",
    "    if not (weights in {'pascal_voc', 'cityscapes', None}):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `pascal_voc`, or `cityscapes` '\n",
    "                         '(pre-trained on PASCAL VOC)')\n",
    "\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('The Deeplabv3+ model is only available with '\n",
    "                           'the TensorFlow backend.')\n",
    "\n",
    "    if not (backbone in {'xception', 'mobilenetv2'}):\n",
    "        raise ValueError('The `backbone` argument should be either '\n",
    "                         '`xception`  or `mobilenetv2` ')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            # Input layer\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if backbone == 'xception':\n",
    "        if OS == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_rate = 2  # ! Not mentioned in paper, but required\n",
    "            exit_block_rates = (2, 4)\n",
    "            atrous_rates = (12, 24, 36)\n",
    "        else:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_rate = 1\n",
    "            exit_block_rates = (1, 2)\n",
    "            atrous_rates = (6, 12, 18)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), strides=(2, 2),\n",
    "                   name='entry_flow_conv1_1', use_bias=False, padding='same')(img_input)\n",
    "        x = BatchNormalization(name='entry_flow_conv1_1_BN')(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = _conv2d_same(x, 64, 'entry_flow_conv1_2', kernel_size=3, stride=1)\n",
    "        x = BatchNormalization(name='entry_flow_conv1_2_BN')(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = _xception_block(x, [128, 128, 128], 'entry_flow_block1',\n",
    "                            skip_connection_type='conv', stride=2,\n",
    "                            depth_activation=False)\n",
    "        x, skip1 = _xception_block(x, [256, 256, 256], 'entry_flow_block2',\n",
    "                                   skip_connection_type='conv', stride=2,\n",
    "                                   depth_activation=False, return_skip=True)\n",
    "\n",
    "        x = _xception_block(x, [728, 728, 728], 'entry_flow_block3',\n",
    "                            skip_connection_type='conv', stride=entry_block3_stride,\n",
    "                            depth_activation=False)\n",
    "        for i in range(16):\n",
    "            x = _xception_block(x, [728, 728, 728], 'middle_flow_unit_{}'.format(i + 1),\n",
    "                                skip_connection_type='sum', stride=1, rate=middle_block_rate,\n",
    "                                depth_activation=False)\n",
    "\n",
    "        x = _xception_block(x, [728, 1024, 1024], 'exit_flow_block1',\n",
    "                            skip_connection_type='conv', stride=1, rate=exit_block_rates[0],\n",
    "                            depth_activation=False)\n",
    "        x = _xception_block(x, [1536, 1536, 2048], 'exit_flow_block2',\n",
    "                            skip_connection_type='none', stride=1, rate=exit_block_rates[1],\n",
    "                            depth_activation=True)\n",
    "\n",
    "    else:\n",
    "        OS = 8\n",
    "        first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "        x = Conv2D(first_block_filters,\n",
    "                   kernel_size=3,\n",
    "                   strides=(2, 2), padding='same',\n",
    "                   use_bias=False, name='Conv')(img_input)\n",
    "        x = BatchNormalization(\n",
    "            epsilon=1e-3, momentum=0.999, name='Conv_BN')(x)\n",
    "        x = Activation(relu6, name='Conv_Relu6')(x)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                                expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                                expansion=6, block_id=1, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                                expansion=6, block_id=3, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=4, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "        # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                                expansion=6, block_id=6, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=7, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=8, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=10, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=11, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                                expansion=6, block_id=13, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=14, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False, name='image_pooling')(b4)\n",
    "    b4 = BatchNormalization(name='image_pooling_BN', epsilon=1e-5)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n",
    "    b0 = BatchNormalization(name='aspp0_BN', epsilon=1e-5)(b0)\n",
    "    b0 = Activation('relu', name='aspp0_activation')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "    if backbone == 'xception':\n",
    "        # rate = 6 (12)\n",
    "        b1 = SepConv_BN(x, 256, 'aspp1',\n",
    "                        rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n",
    "        # rate = 12 (24)\n",
    "        b2 = SepConv_BN(x, 256, 'aspp2',\n",
    "                        rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n",
    "        # rate = 18 (36)\n",
    "        b3 = SepConv_BN(x, 256, 'aspp3',\n",
    "                        rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n",
    "\n",
    "        # concatenate ASPP branches & project\n",
    "        x = Concatenate()([b4, b0, b1, b2, b3])\n",
    "    else:\n",
    "        x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False, name='concat_projection')(x)\n",
    "    x = BatchNormalization(name='concat_projection_BN', epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # DeepLab v.3+ decoder\n",
    "\n",
    "    if backbone == 'xception':\n",
    "        # Feature projection\n",
    "        # x4 (x2) block\n",
    "        x = BilinearUpsampling(output_size=(int(np.ceil(input_shape[0] / 4)),\n",
    "                                            int(np.ceil(input_shape[1] / 4))))(x)\n",
    "        dec_skip1 = Conv2D(48, (1, 1), padding='same',\n",
    "                           use_bias=False, name='feature_projection0')(skip1)\n",
    "        dec_skip1 = BatchNormalization(\n",
    "            name='feature_projection0_BN', epsilon=1e-5)(dec_skip1)\n",
    "        dec_skip1 = Activation('relu')(dec_skip1)\n",
    "        x = Concatenate()([x, dec_skip1])\n",
    "        x = SepConv_BN(x, 256, 'decoder_conv0',\n",
    "                       depth_activation=True, epsilon=1e-5)\n",
    "        x = SepConv_BN(x, 256, 'decoder_conv1',\n",
    "                       depth_activation=True, epsilon=1e-5)\n",
    "\n",
    "    # you can use it with arbitary number of classes\n",
    "    if classes == 21:\n",
    "        last_layer_name = 'logits_semantic'\n",
    "    else:\n",
    "        last_layer_name = 'custom_logits_semantic'\n",
    "\n",
    "    x = Conv2D(classes, (1, 1), padding='same', name=last_layer_name)(x)\n",
    "    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name='deeplabv3plus')\n",
    "\n",
    "    # load weights\n",
    "\n",
    "    if weights == 'pascal_voc':\n",
    "        if backbone == 'xception':\n",
    "            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH_X,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH_MOBILE,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    elif weights == 'cityscapes':\n",
    "        if backbone == 'xception':\n",
    "            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels_cityscapes.h5',\n",
    "                                    WEIGHTS_PATH_X_CS,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels_cityscapes.h5',\n",
    "                                    WEIGHTS_PATH_MOBILE_CS,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
    "    # Returns\n",
    "        Input array scaled to [-1.,1.]\n",
    "    \"\"\"\n",
    "    return imagenet_utils.preprocess_input(x, mode='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1969b1-91dc-4072-a589-d87e1428c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "\n",
    "    def __init__(self, path, split_ratio, x, y, color_space='rgb'):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "        self.color_space = color_space\n",
    "        self.path_train_images = path + \"train/train/image/\"\n",
    "        self.path_train_labels = path + \"train/train/mask/\"\n",
    "        self.image_file_list = get_png_filename_list(self.path_train_images)\n",
    "        self.label_file_list = get_png_filename_list(self.path_train_labels)\n",
    "        self.image_file_list[:], self.label_file_list[:] = self.shuffle_image_label_lists_together()\n",
    "        self.split_index = int(split_ratio * len(self.image_file_list))\n",
    "        self.x_train_file_list = self.image_file_list[self.split_index:]\n",
    "        self.y_train_file_list = self.label_file_list[self.split_index:]\n",
    "        self.x_val_file_list = self.image_file_list[:self.split_index]\n",
    "        self.y_val_file_list = self.label_file_list[:self.split_index]\n",
    "    def generate_data(self, batch_size, train=False, val=False, test=False):\n",
    "        \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "        try:\n",
    "            if train is True:\n",
    "                image_file_list = self.x_train_file_list\n",
    "                label_file_list = self.y_train_file_list\n",
    "            elif val is True:\n",
    "                image_file_list = self.x_val_file_list\n",
    "                label_file_list = self.y_val_file_list\n",
    "            elif test is True:\n",
    "                image_file_list = self.x_test_file_list\n",
    "                label_file_list = self.y_test_file_list\n",
    "        except ValueError:\n",
    "            print('one of train or val or test need to be True')\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            image_batch = []\n",
    "            label_batch = []\n",
    "            for b in range(batch_size):\n",
    "                if i == len(self.x_train_file_list):\n",
    "                    i = 0\n",
    "                if i < len(image_file_list):\n",
    "                    sample_image_filename = image_file_list[i]\n",
    "                    sample_label_filename = label_file_list[i]\n",
    "                    if train or val:\n",
    "                        image = cv2.imread(self.path_train_images + sample_image_filename, 1)\n",
    "                        label = cv2.imread(self.path_train_labels + sample_label_filename, 0)\n",
    "                    elif test is True:\n",
    "                        image = cv2.imread(self.path_test_images + sample_image_filename, 1)\n",
    "                        label = cv2.imread(self.path_test_labels + sample_label_filename, 0)\n",
    "                    # image, label = self.change_color_space(image, label, self.color_space)\n",
    "                    label = np.expand_dims(label, axis=2)\n",
    "                    if image.shape[0] == self.x and image.shape[1] == self.y:\n",
    "                        image_batch.append(image.astype(\"float32\"))\n",
    "                    else:\n",
    "                        print('the input image shape is not {}x{}'.format(self.x, self.y))\n",
    "                    if label.shape[0] == self.x and label.shape[1] == self.y:\n",
    "                        label_batch.append(label.astype(\"float32\"))\n",
    "                    else:\n",
    "                        print('the input label shape is not {}x{}'.format(self.x, self.y))\n",
    "                i += 1\n",
    "            if image_batch and label_batch:\n",
    "                image_batch = normalize(np.array(image_batch))\n",
    "                label_batch = normalize(np.array(label_batch))\n",
    "                yield (image_batch, label_batch)\n",
    "\n",
    "    def get_num_data_points(self, train=False, val=False):\n",
    "        try:\n",
    "            image_file_list = self.x_train_file_list if val is False and train is True else self.x_val_file_list\n",
    "        except ValueError:\n",
    "            print('one of train or val need to be True')\n",
    "\n",
    "        return len(image_file_list)\n",
    "\n",
    "    def shuffle_image_label_lists_together(self):\n",
    "        combined = list(zip(self.image_file_list, self.label_file_list))\n",
    "        random.shuffle(combined)\n",
    "        return zip(*combined)\n",
    "\n",
    "    @staticmethod\n",
    "    def change_color_space(image, label, color_space):\n",
    "        if color_space.lower() is 'hsi' or 'hsv':\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            label = cv2.cvtColor(label, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space.lower() is 'lab':\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "            label = cv2.cvtColor(label, cv2.COLOR_BGR2LAB)\n",
    "        return image, label\n",
    "def normalize(arr):\n",
    "    diff = np.amax(arr) - np.amin(arr)\n",
    "    diff = 255 if diff == 0 else diff\n",
    "    arr = arr / np.absolute(diff)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_png_filename_list(path):\n",
    "    file_list = []\n",
    "    for FileNameLength in range(0, 500):\n",
    "        for dirName, subdirList, fileList in os.walk(path):\n",
    "            for filename in fileList:\n",
    "                if \".png\" in filename.lower() and len(filename) == FileNameLength:\n",
    "                    file_list.append(filename)\n",
    "            break\n",
    "    file_list.sort()\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def get_jpg_filename_list(path):\n",
    "    file_list = []\n",
    "    for FileNameLength in range(0, 500):\n",
    "        for dirName, subdirList, fileList in os.walk(path):\n",
    "            for filename in fileList:\n",
    "                # check file extension\n",
    "                if \".jpg\" in filename.lower() and len(filename) == FileNameLength:\n",
    "                    file_list.append(filename)\n",
    "            break\n",
    "    file_list.sort()\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def load_jpg_images(path):\n",
    "    file_list = get_jpg_filename_list(path)\n",
    "    temp_list = []\n",
    "    for filename in file_list:\n",
    "        img = cv2.imread(path + filename, 1)\n",
    "        temp_list.append(img.astype(\"float32\"))\n",
    "\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list, file_list\n",
    "\n",
    "\n",
    "def load_png_images(path):\n",
    "\n",
    "    temp_list = []\n",
    "    file_list = get_png_filename_list(path)\n",
    "    for filename in file_list:\n",
    "        img = cv2.imread(path + filename, 1)\n",
    "        temp_list.append(img.astype(\"float32\"))\n",
    "\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list, file_list\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    path_train_images = path + \"train/train/images/\"\n",
    "    path_train_labels = path + \"train/train/labels/\"\n",
    "    path_test_images = path + \"test/images/\"\n",
    "    path_test_labels = path + \"test/labels/\"\n",
    "    x_train, train_image_filenames_list = load_png_images(path_train_images)\n",
    "    y_train, train_label_filenames_list = load_png_images(path_train_labels)\n",
    "    x_train = normalize(x_train)\n",
    "    y_train = normalize(y_train)\n",
    "    return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97624fa8-6cbb-4d93-8757-23ce3198f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE =224\n",
    "input_dim_x=224\n",
    "input_dim_y=224\n",
    "n_filters = 32\n",
    "dataset = 'dataset'\n",
    "data_gen = DataGen('C:/Users/tarek/Downloads/wound/' + dataset + '/', split_ratio=0.2, x=input_dim_x, y=input_dim_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731ee35-16d5-445c-9730-1c1082335ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images_bilinear(X, height_factor=1, width_factor=1, target_height=None, target_width=None, data_format='default'):\n",
    "    '''Resizes the images contained in a 4D tensor of shape\n",
    "    - [batch, channels, height, width] (for 'channels_first' data_format)\n",
    "    - [batch, height, width, channels] (for 'channels_last' data_format)\n",
    "    by a factor of (height_factor, width_factor). Both factors should be\n",
    "    positive integers.\n",
    "    '''\n",
    "    if data_format == 'default':\n",
    "        data_format = K.image_data_format()\n",
    "    if data_format == 'channels_first':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[2:]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = K.permute_dimensions(X, [0, 2, 3, 1])\n",
    "        X = tf.image.resize(X, new_shape)\n",
    "        X = K.permute_dimensions(X, [0, 3, 1, 2])\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, None, target_height, target_width))\n",
    "        else:\n",
    "            X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n",
    "        return X\n",
    "    elif data_format == 'channels_last':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[1:3]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = tf.image.resize(X, new_shape)\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, target_height, target_width, None))\n",
    "        else:\n",
    "            X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n",
    "        return X\n",
    "    else:\n",
    "        raise Exception('Invalid data_format: ' + data_format)\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(1, 1), target_size=None, data_format='default', **kwargs):\n",
    "        if data_format == 'default':\n",
    "            data_format = K.image_data_format()\n",
    "        self.size = tuple(size)\n",
    "        if target_size is not None:\n",
    "            self.target_size = tuple(target_size)\n",
    "        else:\n",
    "            self.target_size = None\n",
    "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {tf, th}'\n",
    "        self.data_format = data_format\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            width = int(self.size[0] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[3] if input_shape[3] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    width,\n",
    "                    height)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            width = int(self.size[0] * input_shape[1] if input_shape[1] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    width,\n",
    "                    height,\n",
    "                    input_shape[3])\n",
    "        else:\n",
    "            raise Exception('Invalid data_format: ' + self.data_format)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.target_size is not None:\n",
    "            return resize_images_bilinear(x, target_height=self.target_size[0], target_width=self.target_size[1], data_format=self.data_format)\n",
    "        else:\n",
    "            return resize_images_bilinear(x, height_factor=self.size[0], width_factor=self.size[1], data_format=self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'size': self.size, 'target_size': self.target_size}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da8a7a-fa82-4aab-81f8-1479497ea597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c95e4-86da-4ad5-9622-6f60b5d0c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff09e9-4bcd-4f7d-aa65-ae699bf1911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "loss = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2d7e4-c1b5-4e08-bf04-0d5a17e7c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=False),\n",
    "    ModelCheckpoint('C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\update\\\\mobilenetv2\\\\model-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ee43d-39da-423e-8581-f9f576f1826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.00001\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / ((K.sum(y_true_f) + K.sum(y_pred_f)) + smooth)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603f8d1-638b-4db4-a06f-f679776556d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(truth, prediction):\n",
    "    TP = K.sum(K.round(K.clip(truth * prediction, 0, 1)))\n",
    "    FP = K.sum(K.round(K.clip((1-truth) * prediction, 0, 1)))\n",
    "    return TP / (TP + FP + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d44d7-3978-45b3-8fb9-21f18e525718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(truth, prediction):\n",
    "    TP = K.sum(K.round(K.clip(truth * prediction, 0, 1)))\n",
    "    P = K.sum(K.round(K.clip(truth, 0, 1)))\n",
    "    return TP / (P + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02fb71-d286-43e7-847b-76711c0700f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=[dice_coef, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598540d9-b170-4784-b6b6-4bb113034fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4f016-c8ac-4d56-87cc-41ac1a59390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model,draw_volume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6740b6-26ca-4ddf-8e9f-d0370222e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(data_gen.generate_data(batch_size=batch_size, train=True),\n",
    "                                       steps_per_epoch=int(data_gen.get_num_data_points(train=True) / batch_size),\n",
    "                                       callbacks=[es],\n",
    "                                       validation_data=data_gen.generate_data(batch_size=batch_size, val=True),\n",
    "                                       validation_steps=int(data_gen.get_num_data_points(val=True) / batch_size),\n",
    "                                       epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44715c7-7b9d-4601-9c3a-b49d6bae1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\dataset\\\\test'\n",
    "BATCH=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460291b1-2fe5-4854-9924-2b1e821ee515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1f10d-ca0e-41ef-9c7f-85247f65eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y.set_shape([IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(map_func=tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ff3d7-6e9b-4a24-8ed7-bc80eb95b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "IMAGE_SIZE = 224\n",
    "test_x = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "test_y = sorted(glob(os.path.join(path, \"labels/*\")))\n",
    "test_dataset = tf_dataset(test_x, test_y, batch=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daf5cb-08c1-4bc3-befc-c42812c6c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "with CustomObjectScope({'relu6': relu6,'DepthwiseConv2D': DepthwiseConv2D, 'BilinearUpsampling': BilinearUpsampling}):\n",
    "    model = keras.models.load_model('C:\\\\Users\\\\tarek\\\\Downloads\\\\wound\\\\update\\\\mobilenetv2\\\\model-008.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8747de50-dd3d-46a2-91a4-e8c62d52729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_y))\n",
    "print(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca603520-53ee-42f1-85fe-6dc5a9aacd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics=[dice_coef, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca8e52-bb7b-4b98-b033-f7f8ed11a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = (len(test_x)//BATCH)\n",
    "if len(test_x) % BATCH != 0:\n",
    "    test_steps += 1\n",
    "model.evaluate(test_dataset, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd9654-f76c-4c12-8aa2-86a8ea5c2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab0e9c-b0f9-4a76-9c78-92bb0297ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661e060-541e-4145-945f-b3829072a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(test_x[10:20], test_y[10:20])):\n",
    "    x = read_image(x)\n",
    "    y = read_mask(y)\n",
    "    y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 10, 3))\n",
    "\n",
    "    all_images = [\n",
    "        x, white_line,\n",
    "        mask_parse(y), white_line,\n",
    "        mask_parse(y_pred)\n",
    "    ]\n",
    "    image = np.concatenate(all_images, axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(56, 56))\n",
    "    a = fig.add_subplot(1, 1, 1)\n",
    "    imgplot = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c78c22-6245-4d73-bcde-6296a6bf12ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
